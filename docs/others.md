  1. GitHub Actions - ✅ 推荐保留/添加                                                                                                                                                                         
                  
  即使是个人宏观分析，GitHub Actions 仍有价值：
  ┌──────────────┬───────────────────────────────────────────────────┐
  │     场景     │                      适用性                       │
  ├──────────────┼───────────────────────────────────────────────────┤
  │ 定时数据收集 │ ✅ 每日自动抓取 RSS、财报、宏观数据，无需开着电脑 │
  ├──────────────┼───────────────────────────────────────────────────┤
  │ 零成本运行   │ ✅ 免费，适合个人                                 │
  ├──────────────┼───────────────────────────────────────────────────┤
  │ 历史数据归档 │ ✅ 可将分析结果保存为 Artifacts 或推送回仓库      │
  └──────────────┴───────────────────────────────────────────────────┘
  建议简化配置：
  # 只需要定时触发 + 简单的数据更新
  on:
    schedule:
      - cron: '0 8,18 * * *'  # 每天 8点/18点运行

  不需要的功能：
  - 复杂的部署流程（你本地开发，不需要自动部署）
  - 多环境配置

  ---
  2. ChromaDB - ⚠️  可简化或移除

  当前用于向量搜索（RAG），但基于你的场景：
  ┌──────────────────┬────────┬───────────────────────────────────────────────────┐
  │       功能       │ 必要性 │                     替代方案                      │
  ├──────────────────┼────────┼───────────────────────────────────────────────────┤
  │ 语义搜索历史事件 │ 中等   │ 如果数据量小（<1000条），用 SQLite + 全文搜索足够 │
  ├──────────────────┼────────┼───────────────────────────────────────────────────┤
  │ 相似事件关联     │ 高     │ 可用简单 TF-IDF 或预计算嵌入存储在 JSON           │
  └──────────────────┴────────┴───────────────────────────────────────────────────┘
  建议：
  - 如果目前 ChromaDB 运行良好 → 保留，但考虑 SQLite 模式（ChromaDB 支持 chroma.sqlite 单文件）
  - 如果希望简化 → 移除，改用 文件系统存储（JSON/Markdown）+ 简单索引

  # 简化方案：JSON + 内存索引
  # 足够支撑个人数千条事件的搜索
  import json
  from pathlib import Path

  events = json.loads(Path("data/events.json").read_text())
  # 简单关键词过滤即可满足需求

  ---
  3. PostgreSQL - ❌ 不推荐添加

  基于你的场景，PostgreSQL 过于重型：
  ┌────────────┬──────────────────────────────────────┐
  │    原因    │                 说明                 │
  ├────────────┼──────────────────────────────────────┤
  │ 数据量小   │ 个人宏观分析，事件数据 likely < 10MB │
  ├────────────┼──────────────────────────────────────┤
  │ 无多用户   │ 不需要事务隔离、权限管理             │
  ├────────────┼──────────────────────────────────────┤
  │ 非高频写入 │ 每日两次更新，文件系统足够           │
  ├────────────┼──────────────────────────────────────┤
  │ 部署复杂度 │ 本地需安装/维护 PG，增加负担         │
  └────────────┴──────────────────────────────────────┘
  当前方案已足够：
  - 内存存储（运行时）
  - 文件持久化（JSON/CSV/Markdown）
  - Git 版本控制历史

  ---
  🎯 针对"宏观分析"场景的优化建议

  既然你的目标是判断金融和经济情况，而非交易，建议调整以下功能优先级：

  降低优先级（偏交易向）

  - ❌ 筹码分布分析
  - ❌ 精确买卖点/止损价
  - ❌ 实时推送通知
  - ❌ 回测验证（交易准确率）

  提高优先级（偏宏观向）

  从 daily_stock_analysis 借鉴这些：
  ┌───────────────────┬────────────┬──────────────────────────────────┐
  │       功能        │    价值    │             实现方式             │
  ├───────────────────┼────────────┼──────────────────────────────────┤
  │ 📊 大盘复盘报告   │ ⭐⭐⭐⭐⭐ │ 每日自动生成市场概览 Markdown    │
  ├───────────────────┼────────────┼──────────────────────────────────┤
  │ 📈 多市场关联分析 │ ⭐⭐⭐⭐   │ 分析 A股/港股/美股/外汇的联动    │
  ├───────────────────┼────────────┼──────────────────────────────────┤
  │ 📰 舆情情绪聚合   │ ⭐⭐⭐⭐   │ 整合多源新闻的情绪趋势           │
  ├───────────────────┼────────────┼──────────────────────────────────┤
  │ 📅 宏观日历       │ ⭐⭐⭐     │ 美联储议息、CPI发布等关键事件    │
  ├───────────────────┼────────────┼──────────────────────────────────┤
  │ 📉 自定义指标组合 │ ⭐⭐⭐     │ 美元指数+美债收益率+黄金的相关性 │
  └───────────────────┴────────────┴──────────────────────────────────┘
  ---
  💡 建议的简化架构

  market-intel-dashboard/
  ├── apps/
  │   ├── web/              # Next.js 前端（保留）
  │   └── api/              # FastAPI 后端（简化）
  ├── data/                 # 数据目录（Git 追踪）
  │   ├── events/           # 事件 JSON 文件
  │   ├── reports/          # 每日生成的复盘报告
  │   └── cache/            # 原始数据缓存
  ├── notebooks/            # 分析笔记本（新增）
  └── .github/
      └── workflows/        # GitHub Actions 定时更新

  核心变化：
  1. 移除 ChromaDB → 改用文件系统 + 简单内存索引
  2. 不添加 PostgreSQL → JSON 文件足够
  3. 添加 GitHub Actions → 定时抓取数据并提交回仓库
  4. 新增 notebooks/ → Jupyter 笔记本做深度宏观分析

  ---
  📝 具体建议

  短期（可立即做）

  1. 添加 GitHub Actions 定时更新数据（零成本自动化）
  2. 每日大盘复盘 Markdown 报告（参考 daily_stock_analysis 的格式）

  中期

  3. 事件时间线可视化（宏观事件的因果关系图）
  4. 自定义指标看板（美元指数+美债+黄金+大宗商品的关联面板）
    ---             
  🔍 你项目中 ChromaDB 的具体用途                                                                                                                                                                              
                  
  核心功能：RAG (检索增强生成)                                                                                                                                                                                 
                  
  # 简化流程
  事件 → DashScope 生成向量 → ChromaDB 存储
                                ↓
  用户问题 → DashScope 生成向量 → ChromaDB 相似度搜索 → 返回相关事件 → 提供给 LLM 分析

  具体职责
  ┌────────────┬────────────────────────────────────────┐
  │    功能    │                  说明                  │
  ├────────────┼────────────────────────────────────────┤
  │ 向量存储   │ 存储事件证据的 embedding 向量 (1536维) │
  ├────────────┼────────────────────────────────────────┤
  │ 相似度搜索 │ 用余弦相似度找出与用户问题最相关的事件 │
  ├────────────┼────────────────────────────────────────┤
  │ 元数据过滤 │ 支持按市场、股票代码、事件类型等过滤   │
  ├────────────┼────────────────────────────────────────┤
  │ 上下文构建 │ 为 LLM 提供相关证据，生成更准确的分析  │
  └────────────┴────────────────────────────────────────┘
  ---
  ✅ 不用 ChromaDB，完全可以进行向量分析

  ChromaDB 只是一个向量数据库，向量分析的核心（生成 embedding + 相似度计算）与数据库无关。

  替代方案对比
  ┌─────────────────┬───────────────────────────────────────────┬──────────────────────┬────────┐
  │      方案       │                 实现方式                  │       适用场景       │ 复杂度 │
  ├─────────────────┼───────────────────────────────────────────┼──────────────────────┼────────┤
  │ 内存 + NumPy    │ Python 列表存储向量，NumPy 计算余弦相似度 │ < 5000 条事件        │ ⭐     │
  ├─────────────────┼───────────────────────────────────────────┼──────────────────────┼────────┤
  │ SQLite + Python │ SQLite 存向量和元数据，Python 计算相似度  │ < 50000 条事件       │ ⭐⭐   │
  ├─────────────────┼───────────────────────────────────────────┼──────────────────────┼────────┤
  │ FAISS           │ Facebook 的轻量级向量索引库               │ 海量数据，需快速检索 │ ⭐⭐⭐ │
  ├─────────────────┼───────────────────────────────────────────┼──────────────────────┼────────┤
  │ 删除 RAG 功能   │ 直接用 LLM 分析，不检索相关事件           │ 事件少，直接全量分析 │ ⭐     │
  └─────────────────┴───────────────────────────────────────────┴──────────────────────┴────────┘
  ---
  🎯 针对你的场景（个人 + 宏观分析）的简化方案

  你的数据量级估计：
  - 每日事件：10-50 条（宏观 + 个股）
  - 一年累计：< 20,000 条
  - 实际活跃查询：< 5,000 条

  推荐：方案 1 - 内存 + NumPy（最简单）

  import numpy as np
  from pathlib import Path
  import json
  import hashlib

  class SimpleVectorStore:
      """极简向量存储，替代 ChromaDB"""

      def __init__(self, data_dir: Path):
          self.data_dir = data_dir
          self.vectors: list[np.ndarray] = []  # 向量列表
          self.metadatas: list[dict] = []       # 元数据列表
          self._load()

      def _load(self):
          """从 JSON 文件加载"""
          vector_file = self.data_dir / "vectors.json"
          if vector_file.exists():
              data = json.loads(vector_file.read_text())
              self.vectors = [np.array(v) for v in data["vectors"]]
              self.metadatas = data["metadatas"]

      def save(self):
          """保存到 JSON"""
          self.data_dir.mkdir(parents=True, exist_ok=True)
          vector_file = self.data_dir / "vectors.json"
          vector_file.write_text(json.dumps({
              "vectors": [v.tolist() for v in self.vectors],
              "metadatas": self.metadatas
          }))

      def add(self, text: str, embedding: list[float], metadata: dict):
          """添加向量"""
          self.vectors.append(np.array(embedding))
          self.metadatas.append(metadata)

      def search(self, query_embedding: list[float], top_k: int = 5) -> list[tuple[dict, float]]:
          """余弦相似度搜索"""
          if not self.vectors:
              return []

          query = np.array(query_embedding)
          # 计算余弦相似度
          similarities = []
          for vec in self.vectors:
              sim = np.dot(query, vec) / (np.linalg.norm(query) * np.linalg.norm(vec))
              similarities.append(sim)

          # 取 top_k
          top_indices = np.argsort(similarities)[-top_k:][::-1]
          return [(self.metadatas[i], similarities[i]) for i in top_indices]

  代码改动量

  # 原代码（vector_store.py）
  from chromadb import PersistentClient
  self._client = PersistentClient(path=config.chroma_path)
  self._collection = self._client.get_or_create_collection(...)

  # 新代码
  from .simple_vector_store import SimpleVectorStore
  self._store = SimpleVectorStore(Path(config.data_dir) / "vectors")

  仅需修改 vector_store.py 文件，其他代码完全不用动。

  ---
  📊 各方案的性能对比（估算）

  假设你有 10,000 条事件：
  ┌───────────────┬──────────┬──────────┬──────────┬───────────────────┐
  │     方案      │ 内存占用 │ 搜索耗时 │ 启动时间 │       依赖        │
  ├───────────────┼──────────┼──────────┼──────────┼───────────────────┤
  │ ChromaDB      │ ~200MB   │ ~50ms    │ ~2s      │ chromadb + sqlite │
  ├───────────────┼──────────┼──────────┼──────────┼───────────────────┤
  │ 内存+NumPy    │ ~100MB   │ ~20ms    │ ~0.5s    │ 仅 numpy          │
  ├───────────────┼──────────┼──────────┼──────────┼───────────────────┤
  │ SQLite+Python │ ~50MB    │ ~100ms   │ ~0.3s    │ 仅标准库          │
  ├───────────────┼──────────┼──────────┼──────────┼───────────────────┤
  │ FAISS         │ ~80MB    │ ~5ms     │ ~1s      │ faiss-cpu         │
  └───────────────┴──────────┴──────────┴──────────┴───────────────────┘
  对于个人使用，内存+NumPy 完全足够，搜索 10,000 条只需 20 毫秒。

  ---
  🤔 是否值得替换？

  保留 ChromaDB 的情况

  - 目前运行稳定，不想改动
  - 未来可能扩展到海量数据
  - 需要高级功能（如向量过滤、聚合）

  替换为简化方案的情况

  - 希望减少依赖（ChromaDB 有 sqlite、protobuf 等依赖）
  - 希望数据以纯 JSON 存储，便于版本控制
  - 希望更透明地控制向量存储逻辑

  ---
  💡 我的建议

  既然你是个人使用，数据量小：

  方案 A：保留 ChromaDB（最省事）
  - 它工作得很好，不用折腾
  - 配置简单 chroma_path = "./chroma_db"

  方案 B：改为内存+NumPy（最简洁）
  - 删除一个依赖
  - 数据变成纯 JSON，可用 Git 追踪
  - 代码更透明可控

  不推荐的方案：
  - PostgreSQL（太重）
  - FAISS（需要编译，增加复杂度）

  ---
